import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score


==============================



# Path to the file you saved earlier
file_path = "data-v7.csv"

# Read CSV into DataFrame
df = pd.read_csv(file_path)

# Show first 5 rows
#print(df.head())



===============================


df_f = df[df["S"] == 0].reset_index(drop=True)  # S = 0
df_s = df[df["S"] == 1].reset_index(drop=True)  # S = 1
#print("S = 0 (df_f)")
#print(df_f.head())

#print("\nS = 1 (df_s)")
#print(df_s.head())


=================


# --- internal helper: vectorized haversine (km) ---
def _haversine_km(lat1, lon1, lats2, lons2, R=6371.0):
    lat1, lon1 = np.radians(lat1), np.radians(lon1)
    lats2, lons2 = np.radians(lats2), np.radians(lons2)

    dlat = lats2 - lat1
    dlon = lons2 - lon1
    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lats2) * np.sin(dlon/2.0)**2
    return 2 * R * np.arcsin(np.sqrt(a))


def find_nearest_point(df_s, df_t, not_matching=None, matching_on=None):

    not_matching = not_matching or []
    matching_on = matching_on or []

    nearest_ids = []
    nearest_dists = []

    for _, t in df_t.iterrows():
        filtered = df_s

        # Exclude same values on not_matching columns
        for c in not_matching:
            if c in filtered.columns:
                filtered = filtered[filtered[c] != t[c]]

        # Keep only exact matches on matching_on columns
        for c in matching_on:
            if c in filtered.columns:
                filtered = filtered[filtered[c] == t[c]]

        if filtered.empty:
            nearest_ids.append(None)
            nearest_dists.append(None)
            continue

        dists = _haversine_km(
            t["LT"], t["LG"],
            filtered["LT"].to_numpy(),
            filtered["LG"].to_numpy()
        )
        j = int(np.argmin(dists))
        nearest_ids.append(filtered.iloc[j]["INDEX"])
        nearest_dists.append(float(dists[j]))

    return nearest_ids, nearest_dists


def find_nearest_success(df_s, df_t, not_matching=["INDEX"], matching_on=[]):
    """
    Wrapper: finds nearest points and writes them to df_t.
    """
    idxs, dists = find_nearest_point(
        df_s, df_t,
        not_matching=not_matching,
        matching_on=matching_on
    )
    df_t["NEAREST_INDEX_1"] = idxs
    df_t["NEAREST_DIST_1"] = dists
    return df_t

def find_nearest_failure(df_s, df_t, not_matching=["INDEX"], matching_on=[]):
    """
    Wrapper: finds nearest points and writes them to df_t.
    """
    idxs, dists = find_nearest_point(
        df_s, df_t,
        not_matching=not_matching,
        matching_on=matching_on
    )
    df_t["NEAREST_INDEX_0"] = idxs
    df_t["NEAREST_DIST_0"] = dists
    return df_t
	
	
=================================

df = find_nearest_success(df_s, df)
df = find_nearest_failure(df_f, df)
#df.head()

====================================


def find_n_nearest_points(df_s, df_t, n=5, not_matching=["INDEX"], matching_on=[]):
    nearest_points_list = []
    nearest_dists_list = []
    ratio_1_list = []   # success / n
    ratio_0_list = []   # failure / n

    for _, t in df_t.iterrows():
        filtered = df_s

        # Exclude matches on not_matching cols
        for c in not_matching:
            if c in filtered.columns:
                filtered = filtered[filtered[c] != t[c]]

        # Keep only matches on matching_on cols
        for c in matching_on:
            if c in filtered.columns:
                filtered = filtered[filtered[c] == t[c]]

        if filtered.empty:
            nearest_points_list.append([])
            nearest_dists_list.append([])
            ratio_1_list.append(0.0)
            ratio_0_list.append(0.0)
            continue

        # Compute distances
        dists = _haversine_km(
            t["LT"], t["LG"],
            filtered["LT"].to_numpy(),
            filtered["LG"].to_numpy()
        )

        # Sort and get n nearest
        sorted_idx = np.argsort(dists)[:n]
        nearest_rows = filtered.iloc[sorted_idx]
        nearest_dists = dists[sorted_idx]

        nearest_points = list(nearest_rows["INDEX"])
        nearest_points_list.append(nearest_points)
        nearest_dists_list.append(list(map(float, nearest_dists)))

        # Compute success/failure ratios over n
        success_count = int((nearest_rows["S"] == 1).sum())
        failure_count = int((nearest_rows["S"] == 0).sum())
        # Divide by n (not by available neighbors), as requested
        denom = n if n > 0 else 1
        ratio_1_list.append(success_count / denom)
        ratio_0_list.append(failure_count / denom)

    df_t[f"NEAREST_{n}_INDEX"] = nearest_points_list
    # If you also want distances available, keep the next line; otherwise remove it.
   # df_t[f"NEAREST_{n}_DISTS"] = nearest_dists_list

    # Ratios requested
    df_t[f"{n}_1_ratio"] = ratio_1_list   # success / n
    #df_t[f"{n}_0_ratio"]  = ratio_0_list   # failure / n

    return df_t


================================

df = find_n_nearest_points(df, df.copy(), n=5)

#df.head()

===================================


all_columns = ["NEAREST_DIST_1","NEAREST_DIST_0","5_1_ratio"]

# Create subplots
max_per_row = 4
n = len(all_columns)
rows = math.ceil(n / max_per_row)

fig, axes = plt.subplots(rows, max_per_row, figsize=(5 * max_per_row, 5 * rows), sharey=False)
axes = axes.flatten()  # Flatten in case of multi-row grid

# Loop through and plot each
for i, col in enumerate(all_columns):
    sns.boxplot(x="S", y=col, data=df, ax=axes[i])
    axes[i].set_title(col)
    axes[i].set_xlabel("S")
    axes[i].set_ylabel(col)

for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])
    
plt.tight_layout()
plt.show()

====================================

plt.figure(figsize=(12, 9))

# Plot failure points (S=0) as red filled circles
plt.scatter(df_f["LG"], df_f["LT"], c='red', label='F (S=0)', alpha=0.6, s=50, marker='o')

# Plot success points (S=1) as green filled circles
plt.scatter(df_s["LG"], df_s["LT"], c='green', label='S (S=1)', alpha=0.6, s=60, marker='o')

# Labels and legend
plt.xlabel("LON (LG)", fontsize=12)
plt.ylabel("LAT (LT)", fontsize=12)
plt.title("Spatial Distribution of S and F Points", fontsize=14)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()


=====================================

def plot_point_nearest_centered_buffered(df, index=1, buffer_scale=1.5, nc="NEAREST_5_INDEX"):

    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt

    # --- fetch target row ---
    target_rows = df[df["INDEX"] == index]
    if target_rows.empty:
        print(f"INDEX {index} not found.")
        return
    target_row = target_rows.iloc[0]

    # --- read nearest list (list preferred, but accept comma-separated string) ---
    nearest_val = target_row.get(nc, None)
    if nearest_val is None or (isinstance(nearest_val, list) and len(nearest_val) == 0):
        print("No nearest points found.")
        return

    if isinstance(nearest_val, list):
        nearest_ids = nearest_val
    else:
        # fall back to parsing if it came as a string
        if pd.isna(nearest_val) or str(nearest_val).strip() == "":
            print("No nearest points found.")
            return
        nearest_ids = [int(x.strip()) for x in str(nearest_val).split(",") if x.strip()]

    # --- subset nearest and context ---
    df_nearest = df[df["INDEX"].isin(nearest_ids)]
    if df_nearest.empty:
        print("Nearest IDs present, but none matched rows in df.")
        return

    df_context = df[~df["INDEX"].isin([index] + nearest_ids)]

    # --- compute distances target -> each nearest (vectorized) using _haversine_km ---
    try:
        dists = _haversine_km(
            float(target_row["LT"]),
            float(target_row["LG"]),
            df_nearest["LT"].to_numpy(dtype=float),
            df_nearest["LG"].to_numpy(dtype=float)
        )
    except NameError as e:
        raise NameError(
            "Function _haversine_km is not defined. "
            "Define it before calling this plot function."
        ) from e

    # --- plot ---
    plt.figure(figsize=(10, 8))

    # Plot nearest points (use marker style to distinguish success/failure)
    for (_, row), dist_km in zip(df_nearest.iterrows(), dists):
        # green for success, red for failure (adjust if you prefer different cues)
        color = 'green' if int(row["S"]) == 1 else 'red'
        plt.scatter(row["LG"], row["LT"], c=color, marker='o', s=80)
        plt.text(row["LG"] + 0.02, row["LT"], f"{dist_km:.1f} km", fontsize=9)

    # Plot target point
    target_color = 'green' if int(target_row["S"]) == 1 else 'red'
    plt.scatter(target_row["LG"], target_row["LT"], c=target_color, marker='o', s=150, label='Target')

    # Plot context (lighter markers)
    if not df_context.empty:
        for _, row in df_context.iterrows():
            color = 'green' if int(row["S"]) == 1 else 'red'
            plt.scatter(row["LG"], row["LT"], c=color, marker='x', s=40, alpha=0.5)

    # --- set axis limits with buffer around target + nearest ---
    lats = [float(target_row["LT"])] + df_nearest["LT"].astype(float).tolist()
    lons = [float(target_row["LG"])] + df_nearest["LG"].astype(float).tolist()

    lat_min, lat_max = min(lats), max(lats)
    lon_min, lon_max = min(lons), max(lons)
    lat_range = (lat_max - lat_min) * buffer_scale if lat_max != lat_min else 0.02 * buffer_scale
    lon_range = (lon_max - lon_min) * buffer_scale if lon_max != lon_min else 0.02 * buffer_scale

    lat_center = float(target_row["LT"])
    lon_center = float(target_row["LG"])

    plt.xlim(lon_center - lon_range/2, lon_center + lon_range/2)
    plt.ylim(lat_center - lat_range/2, lat_center + lat_range/2)

    plt.xlabel("Longitude (LG)")
    plt.ylabel("Latitude (LT)")
    plt.title(f"{nc} of Point INDEX={index} (Centered + Buffer)")
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.show()


=============================================

plot_point_nearest_centered_buffered(df_5_s, index=1, buffer_scale=2.5, nc="NEAREST_5_INDEX")

==============================================

N_NEIGHBORS = 5
TOP_K = 8
RANDOM_STATE = 42

# 1) Separate features, target, and IDs
ids = df["INDEX"].copy()
y = df["S"].astype(int)

X = df.drop(
    columns=[
        "S", "INDEX", "F", "PRE", "SHR", "HT", "LT", "LG",
        "NEAREST_INDEX_1", "NEAREST_INDEX_0", "NEAREST_5_INDEX"
    ],
    errors="ignore"
)

# 2) Split data, keeping ids aligned
X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(
    X, y, ids, test_size=0.3, random_state=42, stratify=y
)

# 3) Train
rf = RandomForestClassifier(n_estimators=300, random_state=42)
rf.fit(X_train, y_train)

# 4) Predict
y_pred = rf.predict(X_test)

# 5) Build results DataFrame
results = pd.DataFrame({
    "Actual": y_test.values,
    "Predicted": y_pred
}, index=ids_test.values).sort_index()

# 6) Show metrics and table
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, digits=3))
print("\nTest results:")
print(results)


==========================================

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# ---- CONFIG ----
TEST_SIZE = 0.3
RANDOM_STATE = 42
N_ESTIMATORS = 300
TOP_K = 5   # <- choose how many top features to keep

# ---- PREPARE DATA ----
# Keep INDEX for reporting, exclude from features
ids = df["INDEX"].copy()
y = df["S"].astype(int)

# Drop non-features (adjust as needed; 'errors="ignore"' lets it run if some cols are absent)
X = df.drop(
    columns=[
        "S", "INDEX", "F", "PRE", "SHR", "HT", "LT", "LG",
        "NEAREST_INDEX_1", "NEAREST_INDEX_0", "NEAREST_5_INDEX"
    ],
    errors="ignore"
)

# Split (keep ids aligned for reporting)
X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(
    X, y, ids, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
)

# ---- BASELINE MODEL (ALL FEATURES) ----
rf = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)
y_proba = rf.predict_proba(X_test)[:, 1]

# Test table (INDEX as index)
results_full = pd.DataFrame(
    {"Actual": y_test.values, "Predicted": y_pred, "Prob_1": y_proba},
    index=ids_test.values
).sort_index()

print("=== Baseline (All Features) ===")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, digits=3))

# Feature importances
importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
print("\nTop feature importances (all features):\n", importances.head(15))

print("\nBaseline test table (INDEX, Actual, Predicted, Prob_1):")
print(results_full)

# ---- FEATURE SELECTION: TOP-K BY IMPORTANCE ----
top_features = importances.head(TOP_K).index.tolist()
print(f"\nSelected TOP_{TOP_K} features:", top_features)

X_train_top = X_train[top_features]
X_test_top  = X_test[top_features]

rf_top = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)
rf_top.fit(X_train_top, y_train)

y_pred_top = rf_top.predict(X_test_top)
y_proba_top = rf_top.predict_proba(X_test_top)[:, 1]

results_top = pd.DataFrame(
    {"Actual": y_test.values, "Predicted": y_pred_top, "Prob_1": y_proba_top},
    index=ids_test.values
).sort_index()

print("\n=== After Feature Selection (Top-K) ===")
print("Accuracy:", accuracy_score(y_test, y_pred_top))
print(classification_report(y_test, y_pred_top, digits=3))

print("\nTop-K test table (INDEX, Actual, Predicted, Prob_1):")
print(results_top)


